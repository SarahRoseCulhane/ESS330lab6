[
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "lab6",
    "section": "",
    "text": "#load neccessary libraries\nlibrary(tidyverse)\n\nWarning: package 'readr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'workflowsets' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(glue)\n\nWarning: package 'glue' was built under R version 4.4.3\n\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.3\n\n#download all data and PDF\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n# Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# where we want to download the data ...\nlocal_files   &lt;- glue('data/camels_{types}.txt')\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n# Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\nFirst, I downloaded all the necessary data into my data directory. From the documentation PDF, I was able to figure out that zero_q_freq represents the percentage of days within a given period during which the stream flow (Q) is zero, indicating no flow conditions."
  },
  {
    "objectID": "lab6.html#question-1",
    "href": "lab6.html#question-1",
    "title": "lab6",
    "section": "",
    "text": "#load neccessary libraries\nlibrary(tidyverse)\n\nWarning: package 'readr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'workflowsets' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(glue)\n\nWarning: package 'glue' was built under R version 4.4.3\n\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.3\n\n#download all data and PDF\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n# Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# where we want to download the data ...\nlocal_files   &lt;- glue('data/camels_{types}.txt')\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n# Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\nFirst, I downloaded all the necessary data into my data directory. From the documentation PDF, I was able to figure out that zero_q_freq represents the percentage of days within a given period during which the stream flow (Q) is zero, indicating no flow conditions."
  },
  {
    "objectID": "ESS330lab8.html",
    "href": "ESS330lab8.html",
    "title": "hyperparameter-tuning",
    "section": "",
    "text": "Lab 8: Machine Learning\nFirst, I loaded the necessary libraries\n\nlibrary(tidyverse)\n\nWarning: package 'readr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'workflowsets' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(glue)\n\nWarning: package 'glue' was built under R version 4.4.3\n\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.3\n\nlibrary(tidyverse)\nlibrary(naniar)\n\nWarning: package 'naniar' was built under R version 4.4.3\n\nlibrary(ggpubr)\n\nWarning: package 'ggpubr' was built under R version 4.4.3\n\n\nData Import/Tidy/Transform\nFirst, I read in the data using map, map, read_delim() and powerjoin::power_full_join().\n\n#download all data and PDF\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n# Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# where we want to download the data ...\nlocal_files   &lt;- glue('data/camels_{types}.txt')\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n# Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\nFirst, I visualized the data\n\nvisdat::vis_dat(camels)\n\n\n\n\n\n\n\n\n\nskimr::skim(camels)\n\n\nData summary\n\n\nName\ncamels\n\n\nNumber of rows\n671\n\n\nNumber of columns\n58\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n52\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ngauge_id\n0\n1.00\n8\n8\n0\n671\n0\n\n\nhigh_prec_timing\n0\n1.00\n3\n3\n0\n4\n0\n\n\nlow_prec_timing\n0\n1.00\n3\n3\n0\n4\n0\n\n\ngeol_1st_class\n0\n1.00\n12\n31\n0\n12\n0\n\n\ngeol_2nd_class\n138\n0.79\n12\n31\n0\n13\n0\n\n\ndom_land_cover\n0\n1.00\n12\n38\n0\n12\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\np_mean\n0\n1.00\n3.26\n1.41\n0.64\n2.37\n3.23\n3.78\n8.94\n▃▇▂▁▁\n\n\npet_mean\n0\n1.00\n2.79\n0.55\n1.90\n2.34\n2.69\n3.15\n4.74\n▇▇▅▂▁\n\n\np_seasonality\n0\n1.00\n-0.04\n0.53\n-1.44\n-0.26\n0.08\n0.22\n0.92\n▁▂▃▇▂\n\n\nfrac_snow\n0\n1.00\n0.18\n0.20\n0.00\n0.04\n0.10\n0.22\n0.91\n▇▂▁▁▁\n\n\naridity\n0\n1.00\n1.06\n0.62\n0.22\n0.70\n0.86\n1.27\n5.21\n▇▂▁▁▁\n\n\nhigh_prec_freq\n0\n1.00\n20.93\n4.55\n7.90\n18.50\n22.00\n24.23\n32.70\n▂▃▇▇▁\n\n\nhigh_prec_dur\n0\n1.00\n1.35\n0.19\n1.08\n1.21\n1.28\n1.44\n2.09\n▇▅▂▁▁\n\n\nlow_prec_freq\n0\n1.00\n254.65\n35.12\n169.90\n232.70\n255.85\n278.92\n348.70\n▂▅▇▅▁\n\n\nlow_prec_dur\n0\n1.00\n5.95\n3.20\n2.79\n4.24\n4.95\n6.70\n36.51\n▇▁▁▁▁\n\n\nglim_1st_class_frac\n0\n1.00\n0.79\n0.20\n0.30\n0.61\n0.83\n1.00\n1.00\n▁▃▃▃▇\n\n\nglim_2nd_class_frac\n0\n1.00\n0.16\n0.14\n0.00\n0.00\n0.14\n0.27\n0.49\n▇▃▃▂▁\n\n\ncarbonate_rocks_frac\n0\n1.00\n0.12\n0.26\n0.00\n0.00\n0.00\n0.04\n1.00\n▇▁▁▁▁\n\n\ngeol_porostiy\n3\n1.00\n0.13\n0.07\n0.01\n0.07\n0.13\n0.19\n0.28\n▇▆▇▇▂\n\n\ngeol_permeability\n0\n1.00\n-13.89\n1.18\n-16.50\n-14.77\n-13.96\n-13.00\n-10.90\n▂▅▇▅▂\n\n\nsoil_depth_pelletier\n0\n1.00\n10.87\n16.24\n0.27\n1.00\n1.23\n12.89\n50.00\n▇▁▁▁▁\n\n\nsoil_depth_statsgo\n0\n1.00\n1.29\n0.27\n0.40\n1.11\n1.46\n1.50\n1.50\n▁▁▂▂▇\n\n\nsoil_porosity\n0\n1.00\n0.44\n0.02\n0.37\n0.43\n0.44\n0.46\n0.68\n▃▇▁▁▁\n\n\nsoil_conductivity\n0\n1.00\n1.74\n1.52\n0.45\n0.93\n1.35\n1.93\n13.96\n▇▁▁▁▁\n\n\nmax_water_content\n0\n1.00\n0.53\n0.15\n0.09\n0.43\n0.56\n0.64\n1.05\n▁▅▇▃▁\n\n\nsand_frac\n0\n1.00\n36.47\n15.63\n8.18\n25.44\n35.27\n44.46\n91.98\n▅▇▅▁▁\n\n\nsilt_frac\n0\n1.00\n33.86\n13.25\n2.99\n23.95\n34.06\n43.64\n67.77\n▂▆▇▆▁\n\n\nclay_frac\n0\n1.00\n19.89\n9.32\n1.85\n14.00\n18.66\n25.42\n50.35\n▃▇▅▂▁\n\n\nwater_frac\n0\n1.00\n0.10\n0.94\n0.00\n0.00\n0.00\n0.00\n19.35\n▇▁▁▁▁\n\n\norganic_frac\n0\n1.00\n0.59\n3.84\n0.00\n0.00\n0.00\n0.00\n57.86\n▇▁▁▁▁\n\n\nother_frac\n0\n1.00\n9.82\n16.83\n0.00\n0.00\n1.31\n11.74\n99.38\n▇▁▁▁▁\n\n\ngauge_lat\n0\n1.00\n39.24\n5.21\n27.05\n35.70\n39.25\n43.21\n48.82\n▂▃▇▆▅\n\n\ngauge_lon\n0\n1.00\n-95.79\n16.21\n-124.39\n-110.41\n-92.78\n-81.77\n-67.94\n▆▃▇▇▅\n\n\nelev_mean\n0\n1.00\n759.42\n786.00\n10.21\n249.67\n462.72\n928.88\n3571.18\n▇▂▁▁▁\n\n\nslope_mean\n0\n1.00\n46.20\n47.12\n0.82\n7.43\n28.80\n73.17\n255.69\n▇▂▂▁▁\n\n\narea_gages2\n0\n1.00\n792.62\n1701.95\n4.03\n122.28\n329.68\n794.30\n25791.04\n▇▁▁▁▁\n\n\narea_geospa_fabric\n0\n1.00\n808.08\n1709.85\n4.10\n127.98\n340.70\n804.50\n25817.78\n▇▁▁▁▁\n\n\nfrac_forest\n0\n1.00\n0.64\n0.37\n0.00\n0.28\n0.81\n0.97\n1.00\n▃▁▁▂▇\n\n\nlai_max\n0\n1.00\n3.22\n1.52\n0.37\n1.81\n3.37\n4.70\n5.58\n▅▆▃▅▇\n\n\nlai_diff\n0\n1.00\n2.45\n1.33\n0.15\n1.20\n2.34\n3.76\n4.83\n▇▇▇▆▇\n\n\ngvf_max\n0\n1.00\n0.72\n0.17\n0.18\n0.61\n0.78\n0.86\n0.92\n▁▁▂▃▇\n\n\ngvf_diff\n0\n1.00\n0.32\n0.15\n0.03\n0.19\n0.32\n0.46\n0.65\n▃▇▅▇▁\n\n\ndom_land_cover_frac\n0\n1.00\n0.81\n0.18\n0.31\n0.65\n0.86\n1.00\n1.00\n▁▂▃▃▇\n\n\nroot_depth_50\n24\n0.96\n0.18\n0.03\n0.12\n0.17\n0.18\n0.19\n0.25\n▃▃▇▂▂\n\n\nroot_depth_99\n24\n0.96\n1.83\n0.30\n1.50\n1.52\n1.80\n2.00\n3.10\n▇▃▂▁▁\n\n\nq_mean\n1\n1.00\n1.49\n1.54\n0.00\n0.63\n1.13\n1.75\n9.69\n▇▁▁▁▁\n\n\nrunoff_ratio\n1\n1.00\n0.39\n0.23\n0.00\n0.24\n0.35\n0.51\n1.36\n▆▇▂▁▁\n\n\nslope_fdc\n1\n1.00\n1.24\n0.51\n0.00\n0.90\n1.28\n1.63\n2.50\n▂▅▇▇▁\n\n\nbaseflow_index\n0\n1.00\n0.49\n0.16\n0.01\n0.40\n0.50\n0.60\n0.98\n▁▃▇▅▁\n\n\nstream_elas\n1\n1.00\n1.83\n0.78\n-0.64\n1.32\n1.70\n2.23\n6.24\n▁▇▃▁▁\n\n\nq5\n1\n1.00\n0.17\n0.27\n0.00\n0.01\n0.08\n0.22\n2.42\n▇▁▁▁▁\n\n\nq95\n1\n1.00\n5.06\n4.94\n0.00\n2.07\n3.77\n6.29\n31.82\n▇▂▁▁▁\n\n\nhigh_q_freq\n1\n1.00\n25.74\n29.07\n0.00\n6.41\n15.10\n35.79\n172.80\n▇▂▁▁▁\n\n\nhigh_q_dur\n1\n1.00\n6.91\n10.07\n0.00\n1.82\n2.85\n7.55\n92.56\n▇▁▁▁▁\n\n\nlow_q_freq\n1\n1.00\n107.62\n82.24\n0.00\n37.44\n96.00\n162.14\n356.80\n▇▆▅▂▁\n\n\nlow_q_dur\n1\n1.00\n22.28\n21.66\n0.00\n10.00\n15.52\n26.91\n209.88\n▇▁▁▁▁\n\n\nzero_q_freq\n1\n1.00\n0.03\n0.11\n0.00\n0.00\n0.00\n0.00\n0.97\n▇▁▁▁▁\n\n\nhfd_mean\n1\n1.00\n182.52\n33.53\n112.25\n160.16\n173.77\n204.05\n287.75\n▂▇▃▂▁\n\n\n\n\n\nThen, I cleaned the data and did a quick visualization of q_mean\n\n# remove remaining missing values\ncamels_clean &lt;- camels %&gt;%\n  drop_na()\n# keep guage_lat and guage_lon for later\ncamels_clean &lt;- camels_clean %&gt;%\n  select(q_mean, everything(), gauge_lat, gauge_lon)\n\n# Quick visualization of q_mean\nggdensity(camels_clean$q_mean, \n          main = \"Density plot of Mean Streamflow (q_mean)\", \n          xlab = \"q_mean\")\n\n\n\n\n\n\n\n\n\nData Splitting\nThen, I split the data into a training and testing set and built resamples using the vfold_cv() function to generate 10 k-fold samples for cross-validation.\n\nset.seed(123)\ncamels_clean &lt;- camels_clean %&gt;%\n  mutate(logQmean = log(q_mean))\n\ncamels_split &lt;- initial_split(camels_clean, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\n\nFeature Engineering\nThen, I created a recipe using aridity and p_mean as the predictors, cleaning up the data\n\nlibrary(tidymodels)\n\n# Create a recipe to preprocess the data\nrec &lt;-  recipe(q_mean ~ aridity + p_mean, data = camels_train) %&gt;%\n  # Log transform the predictor variables (aridity and p_mean)\n  step_log(all_predictors()) %&gt;%\n  # Add an interaction term between aridity and p_mean\n  step_interact(terms = ~ aridity:p_mean) |&gt; \n  # Drop any rows with missing values in the pred\n  step_naomit(all_predictors(), all_outcomes())\n\n#Bake Data\nbaked_data &lt;- prep(rec, camels_train) %&gt;%\n  bake(new_data = NULL)\n\n\n\nResampling and Model Testing\n\nBuild Candidate Models\n\n  # Linear regression model\nlin_mod &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\n# Random forest model\nrf_mod &lt;- rand_forest(trees = 500) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\n# Boosted tree model\nxgb_mod &lt;- boost_tree(trees = 500, learn_rate = 0.1) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\ndefine workflows\n\n\n# Random Forest Workflow\nrf_workflow &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(rf_mod)\n\n#Boosted tree model\nxgb_workflow &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model (xgb_mod)\n\n#linear regression model\nlin_workflow &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lin_mod)\n\nThen, I tested the models\n\nmy_metrics &lt;- metric_set(rmse, rsq, mae)\n\nwf_set &lt;- workflow_set(\n  preproc = list(my_recipe = rec),\n  models = list(\n    xgboost = xgb_mod,\n    random_forest = rf_mod,\n    linear_reg = lin_mod\n  )\n)  \n    \nwf_results &lt;- wf_set %&gt;%\n  workflow_map(\n    \"fit_resamples\",\n    resamples = camels_cv,\n    metrics = my_metrics,\n    control = control_resamples(save_pred = TRUE)\n  )\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\n\nWarning: package 'ranger' was built under R version 4.4.3\n\nautoplot(wf_results)\n\n\n\n\n\n\n\n\n4. Model Selection\nBased on the visualized metrics, I am going to use the random forest model. This model outperformed the other models, ranking as the number one model when using the rank_results() function and the autoplot function. Looking at it, it also had the highest rsq. and the lowest rmse, supporting the outputted table. The model I selected is an ensemble learning method model type with multiple engine types. The most popular ones are the randomForest engine and the Ranger engine. For the purpose of this exercise, I am going to ue the ranger engine. The two common modes are classification and regression. For this one, I am using regression. I think the randomforest model is performing well it is good at handling non-linear relationships, and streamflow probably does not have a linear relationship with predictors like aridity and precipitation\n\n\nModel Tuning\n\nBuild a model for chosen specification\n\n\n# Define a tunable random forest model\nrf_tune_mod &lt;- rand_forest(\n  mtry = tune(),\n  min_n = tune(),\n) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nI used the code abovee to build a model. The hyperparameters I chose to tune are mtry and min_n. The metry hyperparameters referrs to the number of variables randomly sampled as candidates at each split and the min_n hyperparameter is an integer for the minimum number of data points in a node that are required for the node to be split further.\n\nCreate a workflow\n\n\n  # Build a workflow with the tunable random forest model and the recipe\nrf_tune_workflow &lt;- workflow() %&gt;%\n  add_model(rf_tune_mod) %&gt;%\n  add_recipe(rec)\n\nI used the code above to create a workflow.\n\nCheck the Tunable Values/Ranges\n\nfirst, I extracted the tunable parameters. Then I used the dials$object slot to see the tunable parameters and their ranges\n\n# Extract tunable parameter set from the workflow\ndials &lt;- extract_parameter_set_dials(rf_tune_workflow)\n\n# View the parameters and their default ranges\ndials$object \n\n[[1]]\n# Randomly Selected Predictors (quantitative)\nRange: [1, ?]\n\n[[2]]\nMinimal Node Size (quantitative)\nRange: [2, 40]\n\n\n\n\n4. Define the Search Space\n\n# Finalize the mtry and min_n parameters\nrf_params &lt;- parameters(\n  mtry(range = c(1L, 3L)),\n  min_n()\n)\n\n# Finalize the parameter grid based on the dataset (using the data from training set)\nrf_params &lt;- finalize(rf_params, training(camels_split))  # Replace camels_split with your training data\n\n# Generate a space-filling grid of hyperparameters (size = 25 combinations)\nmy_grid &lt;- grid_space_filling(rf_params, size = 25)\n\nWhen I tried to use grid_latin_hypercute(), Rstudio gave me the following error message: “Warning: grid_latin_hypercube() was deprecated in dials 1.3.0.Please use grid_space_filling()” so I used the grid_space_filling function instead. I was also unsure of what to put for dial size. The instructions on the lab said 20 but the rubric said 25 so I just whent with 25.\n\n\n5. Tune the model\n\nmodel_params &lt;-  tune_grid(\n    rf_tune_workflow,\n    resamples = camels_cv,\n    grid = my_grid,\n    metrics = metric_set(rmse, rsq, mae),\n    control = control_grid(save_pred = TRUE)\n  )\n\nautoplot(model_params)\n\n\n\n\n\n\n\n\nBased on this, I see that only having 1 randomly selected predictor producer the best result. This makes sense because I only have one predictor in my recipe and did chose the mtry hyperparameter. Now I know that was maybe not the best hyperparameter to go with but at this point I am going to stick with it. As for the minimal mode size, I see that as the number of nodes increase, the rsq goes down and the rmse and mae goes up, which tells me that the best node size is going to be somewhere in the lower range.\n\n\n6. check the skills of the tuned model\n\n# Collect all metrics from the tuned model\nmodel_metrics &lt;- collect_metrics(model_params)\n\n# View the collected metrics\nmodel_metrics\n\n# A tibble: 75 × 8\n    mtry min_n .metric .estimator  mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1     1    24 mae     standard   0.328    10 0.0200  Preprocessor1_Model01\n 2     1    24 rmse    standard   0.501    10 0.0365  Preprocessor1_Model01\n 3     1    24 rsq     standard   0.913    10 0.00840 Preprocessor1_Model01\n 4     1    13 mae     standard   0.326    10 0.0200  Preprocessor1_Model02\n 5     1    13 rmse    standard   0.498    10 0.0357  Preprocessor1_Model02\n 6     1    13 rsq     standard   0.914    10 0.00709 Preprocessor1_Model02\n 7     1    33 mae     standard   0.335    10 0.0192  Preprocessor1_Model03\n 8     1    33 rmse    standard   0.526    10 0.0351  Preprocessor1_Model03\n 9     1    33 rsq     standard   0.909    10 0.00866 Preprocessor1_Model03\n10     1     5 mae     standard   0.328    10 0.0185  Preprocessor1_Model04\n# ℹ 65 more rows\n\n\nWhen I used the collect_metrics() function, I see a 54x8 tibble with different combonations of mtry and min_n, the hyperparameters I chose to tune for my model. I also see the different metrics; mae, rsq, and rmse, and the resulting statistics. The only value for mtry I am getting is one, which, again, makes sense because my recipe did only use one predictor.\n\n# Show the best model based on MAE\nshow_best(model_params, metric = \"mae\")\n\n# A tibble: 5 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1     1    13 mae     standard   0.326    10  0.0200 Preprocessor1_Model02\n2     1    11 mae     standard   0.327    10  0.0201 Preprocessor1_Model08\n3     1    19 mae     standard   0.328    10  0.0201 Preprocessor1_Model05\n4     1     5 mae     standard   0.328    10  0.0185 Preprocessor1_Model04\n5     1    24 mae     standard   0.328    10  0.0200 Preprocessor1_Model01\n\n\nI used the code above to Use the show_best() function to show the best performing hyperparameter set for my model based on Mean Absolute Error. The best performing hyperparameter set, based on this table, is the one with a mtry of 1 and a min_n of 11.\n\n# Select the best hyperparameter set\nhp_best &lt;- select_best(model_params, metric = \"mae\")\n\n# View the best hyperparameter set\nhp_best\n\n# A tibble: 1 × 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     1    13 Preprocessor1_Model02\n\n\nI used the code above to save the best performing hyperparameter set to an object called hp_best.It looks like the best model has a mtry of one ad a min_n of 13\n\n\n7. Finalize your model\n\n# Finalize the workflow with the best hyperparameters\nfinal_rf_workflow &lt;- finalize_workflow(\n  rf_tune_workflow,  # Original workflow\n  hp_best            # Best hyperparameters obtained from tune_grid\n)\n\n# View the finalized workflow\nfinal_rf_workflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_log()\n• step_interact()\n• step_naomit()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = 1\n  min_n = 13\n\nComputational engine: ranger \n\n# Fit the final model on the full training data\nfinal_rf_model &lt;- fit(final_rf_workflow, data = training(camels_split))  # Replace with your actual training data\n\n# View the final fitted model\nfinal_rf_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_log()\n• step_interact()\n• step_naomit()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~1L,      x), min.node.size = min_rows(~13L, x), num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1)) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      405 \nNumber of independent variables:  3 \nMtry:                             1 \nTarget node size:                 13 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       0.2645582 \nR squared (OOB):                  0.9018331 \n\n\nI ran finalize_workflow() to create a final workflow object\n\n\n8. Final Model Verification\n\n# use last_fit() to fit the final model to the training data and validate it on the test data\nfinal_results &lt;- last_fit(\n  final_rf_workflow,\n  split = camels_split, \n  metrics = metric_set(rmse, rsq, mae)  # Metrics for evaluation\n)\n\n\n# Collect metrics for the final model\nfinal_metrics &lt;- collect_metrics(final_results)\n\n# View the performance on the test set\nfinal_metrics\n\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.415 Preprocessor1_Model1\n2 rsq     standard       0.928 Preprocessor1_Model1\n3 mae     standard       0.304 Preprocessor1_Model1\n\n\nBased on the final model fit, the final model performed worse than the training model set. It has a slightly lower rsq and higher rsme.\n\n# Collect predictions for the final model on the test data\nfinal_predictions &lt;- collect_predictions(final_results)\n\n# View the first few predictions to make sure the object was created\nhead(final_predictions)\n\n# A tibble: 6 × 5\n  .pred id                .row q_mean .config             \n  &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;               \n1  1.99 train/test split     1   2.17 Preprocessor1_Model1\n2  1.87 train/test split    15   1.86 Preprocessor1_Model1\n3  2.26 train/test split    17   2.24 Preprocessor1_Model1\n4  2.09 train/test split    19   2.15 Preprocessor1_Model1\n5  1.97 train/test split    28   2.03 Preprocessor1_Model1\n6  1.17 train/test split    37   1.10 Preprocessor1_Model1\n\nfinal_fit_ful &lt;- fit(final_rf_workflow, data = camels_clean)\n\nLooking at this table, the .pred object was created successfully.\n\n\nplot predicted vs actual\n\nlibrary(ggplot2)\n\nggplot(final_predictions, aes(x = .pred, y = q_mean)) +\n  geom_point(color = \"red\", alpha = 0.6) +\n  geom_smooth(method = \"lm\", color = \"blue\") +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"black\") +\n  labs(\n    title = \"predicted vs actual values\",\n    x = \"predicted\",\n    y = \"actual\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nNow, I will two different maps. One will be of predicted q_mean and the other will be of residuals.\n\nlibrary(ggplot2)\nlibrary(sf)\n\nWarning: package 'sf' was built under R version 4.4.3\n\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\npredictions_all &lt;- augment(final_fit_ful, new_data = camels_clean)\n\npredictions_all &lt;- predictions_all %&gt;%\n  mutate(residual = (q_mean -.pred))\n\npred_map &lt;- ggplot(predictions_all, aes(x = gauge_lon, y = gauge_lat, color = .pred)) +\n  geom_point(size = 2) +\n  scale_color_viridis_c(name = \"predicted\") +\n  labs(title = \"predicted q_mean\") +\n  coord_fixed() +\n  theme_minimal()\n\nresid_map &lt;- ggplot(predictions_all, aes(x = gauge_lon, y = gauge_lat, color = residual)) +\n  geom_point(size = 2) +\n  scale_color_viridis_c(name = \"Residuals\") +\n  labs(title = \"residuals\") +\n  coord_fixed() +\n  theme_minimal()\nlibrary(patchwork)\n\npred_map + resid_map"
  }
]